{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSKp2lyyywOJ"
      },
      "source": [
        " **This is the lab assignment for ENPM 690 Spring 2022. Please do not distribute this collab file without permission.**\n",
        "\n",
        "Created on Fri Mar 28 16:58:59 2022\n",
        "\n",
        "@author: Ruiqi\n",
        "\n",
        "\n",
        "Import required packages\n",
        "\n",
        "If you prefer to use your own complier, those are the things you probably need to do:\n",
        "\n",
        "- You could download and install pytorch from https://pytorch.org/\n",
        "\n",
        "- Other packages could be installed via pip or conda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "970ILJMeC4TD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlIV_1wcGy-G"
      },
      "source": [
        "You could download the LFW dataset using the following command:\n",
        "\n",
        "    wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "    tar -xvzf lfw.tgz\n",
        "    find lfw -iname \"*jpg\" > images_list.txt\n",
        "\n",
        "You could also directly download and process the data using torchvision.\n",
        "Please check:\n",
        "  1. https://pytorch.org/vision/main/generated/torchvision.datasets.LFWPeople.html\n",
        "  2. https://pytorch.org/vision/main/generated/torchvision.datasets.LFWPairs.html\n",
        "  \n",
        "If you directly use pytorch to download and process the data, then you would\n",
        "not need to implement the following processes.\n",
        "\n",
        "\n",
        "If you use the command lines to download the datasets, you will have a\n",
        "dataset folder named lfw and a txt file with lines format as:\n",
        "\n",
        "  lfw/Allan_Wagner/\n",
        "\n",
        "  lfw/Allan_Wagner/Allen_Wagner_0001.jpg\n",
        "\n",
        "  lfw/Alejandro_Fernandez/\n",
        "\n",
        "  lfw/Alejandro_Fernandez/Alejandro_Fernandez_0001.jpg\n",
        "\n",
        "  ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqL4s_hgzjk-",
        "outputId": "a589ab24-2770-4859-a8d9-c38355a40e62"
      },
      "outputs": [],
      "source": [
        "! wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "! tar -xvzf lfw.tgz\n",
        "! find lfw -iname \"*jpg\" > images_list.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAtMZhW1zRPA"
      },
      "source": [
        "**Pre-pocess data**\n",
        "\n",
        "400 persons are in the test set and 400 persons are included in the\n",
        "validation set. The remainings are used for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjGCUsKLzUZB",
        "outputId": "97d2ab9c-8b1e-4b46-f32c-e1dd2f2ff94a"
      },
      "outputs": [],
      "source": [
        "images_dict = {}\n",
        "count = 0\n",
        "for line in open(\"images_list.txt\",\"r\"):\n",
        "    line = line.strip()\n",
        "    person = line.split(\"/\")[-2]\n",
        "    if person not in images_dict:\n",
        "        images_dict[person] = [line]\n",
        "    else:\n",
        "        images_dict[person].append(line)\n",
        "    count += 1\n",
        "\n",
        "print(\"Number of unique persons = \", str(len(images_dict)))\n",
        "print(\"NUmber of total images = \", str(count))\n",
        "unique_ids = list(images_dict.keys())\n",
        "val_ids = unique_ids[-800:-400]\n",
        "test_ids = unique_ids[-400:]\n",
        "train_ids = unique_ids[:-800]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiShOb6jz4c9"
      },
      "source": [
        "Defining pytorch dataset class with return paired data (2 faces) and a label\n",
        "(0 or 1) which verify if the faces belong to the same person or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHi48axEz9f7"
      },
      "outputs": [],
      "source": [
        "class LFW_dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, split=\"train\", images_dict=images_dict, ids=train_ids):\n",
        "    self.split = split\n",
        "    self.images_dict = images_dict\n",
        "    self.ids = ids\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    id1 = self.ids[index]\n",
        "    if len(self.images_dict[id1]) == 1:\n",
        "      id2 = np.random.randint(0, len(self.ids))\n",
        "      id2 = self.ids[id2]\n",
        "      label = 0\n",
        "    else:\n",
        "      id2 = id1\n",
        "      label = 1\n",
        "    img1 = Image.open(self.images_dict[id1][0])\n",
        "    img2 = Image.open(random.sample(self.images_dict[id2], 1)[0])\n",
        "    img1 = transforms.ToTensor()(img1)\n",
        "    img2 = transforms.ToTensor()(img2)\n",
        "    if label == 0:\n",
        "      label = torch.Tensor([1, 0])\n",
        "    else:\n",
        "      label = torch.Tensor([0, 1])\n",
        "    img = torch.cat((img1, img2), 0)\n",
        "    return img, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bbBulJJ0Azc"
      },
      "source": [
        "Define pytorch dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhLwFYfD0JTD"
      },
      "outputs": [],
      "source": [
        "train_dataset = LFW_dataset()\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
        "val_dataset = LFW_dataset(split=\"val\", )\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, shuffle=True, batch_size=32)\n",
        "test_dataset = LFW_dataset(split=\"test\", images_dict=images_dict, ids=test_ids)\n",
        "test_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
        "\n",
        "# for i, data in enumerate(train_dataloader, 0):\n",
        "#         # Get inputs\n",
        "#         inputs, lables = data\n",
        "#         print(inputs.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9cx38kf5ymf"
      },
      "source": [
        "# ** You need to fill out the following code to build up your own model and define your training, testing and main functions. Please do not directly use the models that stored in pytorch. You have to build your own model. Specifically, you need to define a network class with your network architecture.**\n",
        "\n",
        "**If you are new to pytroch, you could find tutorials on https://pytorch.org/tutorials/**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1GuRGHFuukT"
      },
      "source": [
        "Define your network architecture here (5 points): \n",
        "\n",
        "(Hint: you need to decide what type of network you would like to use first. If it is a CNN, then you need to define convolutional layers and fully-connected layers in the init function, and activation layers in the forward function. Please remember, your network only need to have two output: 0 or 1.)\n",
        "\n",
        "You could use a small network model first, to see if your code works or not. Otherwise, you may waste a lot of time on training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF5_mM_j8Lkz"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(6, 32, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 5)\n",
        "        self.fc1 = nn.Linear(32 * 59 * 59, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F6GWI6R8TNB"
      },
      "source": [
        "Define your training process here (5 points):\n",
        "\n",
        "(Hint: In this part, you need to define your loss function and code for your backpropagation process. Remember to return your training loss, cause you need to print out your result after each epoch to see if they are converging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aVMNY9a8v3T"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer):\n",
        "\n",
        "    loss_function = nn.MSELoss() \n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Get inputs\n",
        "        inputs, lables = data\n",
        "        inputs, lables = inputs.to(device), lables.to(device)\n",
        "\n",
        "        # Zero the model gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, lables)\n",
        "        loss.backward()\n",
        "        optimizer.step() # Perfrom learning step\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    running_loss = running_loss / len(train_loader)\n",
        "\n",
        "    return running_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plIjamoY9Gfx"
      },
      "source": [
        "Define your testing process here (5 points):\n",
        "\n",
        "(Hint: You need to evaluate your model at each epoch. Basically, you need to feed your test data into the model you trained before and calculate the accuracy of your model for each epoch. In this part, you still need to return the testing loss to monitor whether the results are converging or if overfitting happens)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRQJQdfK9JPE"
      },
      "outputs": [],
      "source": [
        "def test(model, device, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_function = nn.MSELoss() \n",
        "    test_loss = 0 \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 0):\n",
        "            images, lables = data\n",
        "            images, lables = images.to(device), lables.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += lables.size(0)\n",
        "            correct += (predicted.argmax() == lables.argmax(1)).type(torch.float).sum().item()\n",
        "\n",
        "            loss = loss_function(outputs, lables)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "    test_loss = test_loss / len(test_loader)\n",
        "\n",
        "    return test_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4wGqnJB9OR2"
      },
      "source": [
        "Define your main function to train your model here (5 points):\n",
        "\n",
        "(Hint:Here you need to define your optimization method and call the train and test function for each epoch)\n",
        "\n",
        "***Please print out your training loss, testing loss and accuracy after each epoch***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "VExBsx2j9gJa",
        "outputId": "90381e78-1a48-4e57-b482-ae9b132cf9da"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "batch_size = 32\n",
        "num_epoch = 30\n",
        "    \n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "    \n",
        "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "model = Net().to(device)\n",
        "# print(model)\n",
        "\n",
        "# You can start your code here\n",
        "#################################################\n",
        "lr = 0.000001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr) # lr is learning rate\n",
        "\n",
        "# Training loop\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    running_loss = train(model, device, train_dataloader, optimizer)\n",
        "    print(f'Epoch: {epoch} loss: {running_loss}')\n",
        "    test_loss, model_accuracy = test(model, device, test_dataloader,)\n",
        "    print(f'Epoch: {epoch} loss: {test_loss} Model Accuracy: {model_accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#################################################\n",
        "\n",
        "end_time = time.time()\n",
        "elasped_time = end_time-start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFbNFn2oyiI7"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), f'models/model_lr{lr}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_learning_rate = 0.001\n",
        "torch.load(f'models/model_lr{model_learning_rate}.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ENPM690_lab_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
